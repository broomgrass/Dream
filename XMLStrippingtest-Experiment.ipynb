{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a quick little notebook where I chart my experiments with prepping texts for text mining. Primarily, this means stripping XML and headers. Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"C:/Users/ASUS/Documents/iPython/data/DREaM/withXML/traveltraining/1698 1698 - T C - The New atlas or Travels.xml\", \"r\", encoding=\"utf8\") as f:\n",
    "    testFile = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version='1.0'?><EEBO><dreamheader>\n",
      "  <tcpdata>\n",
      "    <tcpid phase=\"2\">A31298.hdr</tcpid>\n",
      "    <fileDesc>\n",
      "      <titleStmt>\n",
      "        <title>The New atlas, or, Travels and voyages in Europe, Asia, Africa, and America, thro' the most renowned parts of the world ... performed by an English gentleman, in nine years travel and voyages, more exact than ever.</title>\n",
      "        <author>T. C.</author>\n",
      "     \n"
     ]
    }
   ],
   "source": [
    "print(testFile[:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try remove the XML tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(testFile, \"xml\") # testFile is the source doc\n",
    "\n",
    "for text in soup.find_all(\"TEXT\"):\n",
    "    print(text.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "A31298.hdr\n",
      "\n",
      "\n",
      "The New atlas, or, Travels and voyages in Europe, Asia, Africa, and America, thro' the most renowned parts of the world ... performed by an English gentleman, in nine years travel and voyages, more exact than ever.\n",
      "T. C.\n",
      "\n",
      "\n",
      "1698.\n",
      "London :\n",
      "Printed for J. Cleave ... and A. Roper ...,\n",
      "\n",
      "12251058\n",
      "Wing C139.\n",
      "Arber's Term cat. III 138.\n",
      "57084\n",
      "A31298\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The New atlas, or, Travels and voyag  &&&&&&&   Questions, of where I had been, and the particulars of what I observed, at the Request of those that had done so well for me, and now so Lovingly received me, I took leisure time to Write what you have perused, hoping it will give my Country-Men as an entire satisfaction as I have had, in the undertaking and performing my Travels, and then no doubt but both of us will be well pleased.\n",
      "FINIS.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testSoup = BeautifulSoup(testFile, \"xml\")\n",
    "testSoupText = testSoup.text\n",
    "print(testSoupText[:400],\" &&&&&&& \", testSoupText[-400:]) # have a peek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! But the header is still in there. Let's try remove the it. First, it seems easiest to just select the text using tags that all the documents will have - so, for example, /dreamheader at the beginning and /EEBO at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = testFile.find(\"</dreamheader>\")\n",
    "end = testFile.find(\"></EEBO>\")\n",
    "testFileNoHead = testFile[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</dreamheader><TEXTS type='varded' set='cleaned' match='45' date='2015-06-10' version='2.0' metadata='dream'><TEXT LANG=\"eng\">\n",
      "<FRONT>\n",
      "<DIV1 TYPE=\"title page\">\n",
      "<PB REF=\"1\"/>\n",
      "<PB REF=\"1\" MS=\"y\"/>\n",
      "<P> THE NEW ATLAS: OR, Travels and Voyages IN Europe, Asia, Africa and America, <normalised orig=\"Thro'\" auto=\"true\">Through</normalised> the most Renowned Parts of the WORLD, VIZ.</P>\n",
      "<P>From England to t  ||||||||||||||||  at the Request of those that had done so well for me, and now so Lovingly received me, I took leisure time to Write what you have perused, hoping it will give my Country-Men as an entire satisfaction as I have had, in the undertaking and performing my Travels, and then no doubt but both of us will be well pleased.</P>\n",
      "<TRAILER>FINIS.</TRAILER>\n",
      "<PB REF=\"126\"/>\n",
      "</DIV2>\n",
      "</DIV1>\n",
      "</BODY>\n",
      "</TEXT></TEXTS\n"
     ]
    }
   ],
   "source": [
    "print(testFileNoHead[:400], \" |||||||||||||||| \", testFileNoHead[-400:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems to give the text that we want! hurrah. Now let's remove the XML from our core text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soupNoHead = BeautifulSoup(testFileNoHead, \"xml\") # string is the source doc\n",
    "\n",
    "for text in soupNoHead.find_all(\"TEXT\"):\n",
    "    print(text.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ||||||||||||  \n"
     ]
    }
   ],
   "source": [
    "testSoupNoHead = BeautifulSoup(testFileNoHead, \"xml\")\n",
    "testSoupTextNoHead = testSoupNoHead.text\n",
    "print(testSoupTextNoHead[:40000],\" |||||||||||| \", testSoupText2[-400:]) # have a peek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Hmm. I tried removing the header before removing the XML, but that...did not work. Maybe Beautiful Soup can't pick it up unless the starting tag is complete? Unsure.\n",
    "\n",
    "In any case, does it matter if the headers are in there, if every single text will have nearly the same header? Hmm, yes, I think it will still be a problem, because they won't be exactly the same. Not sure if that will be enough to skew results.\n",
    "\n",
    "What if we do a start/end with the plain text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = testSoupText2.find(\"tcpid.\")\n",
    "end = testSoupText2.find(\"FINIS\") # how to get to the end\n",
    "testNoHeader2 = testSoupText2[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(testNoHeader2[:200]) # Yup, doesn't look like there is anything in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "A31298.hdr\n",
      "\n",
      "\n",
      "The New atlas, or, Travels and voyages in Europe, Asia, Africa, and America, thro' the most renowned parts of the world ... performed by an English gentleman, in nine years travel and voyages, more exact than ever.\n",
      "T. C.\n",
      "\n",
      "\n",
      "1698.\n",
      "London :\n",
      "Printed for J. Cleave ... and A. Roper ...,\n",
      "\n",
      "12251058\n",
      "Wing C139.\n",
      "Arber's Term cat. III 138.\n",
      "57084\n",
      "A31298\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The New atlas, or, Travels and voyages in Europe, Asia, Africa, and America, thro' the most renowned parts of the world\n",
      "The New atlas, or, Travels and voyages in Europe, Asia, Africa, and America, thro' the most renowned parts of the world ... performed by an English gentleman, in nine years travel and voyages, more exact than ever\n",
      "New atlas\n",
      "\n",
      "T. C.\n",
      "unknown\n",
      "0\n",
      "0\n",
      "93425138\n",
      "\n",
      "\n",
      "\n",
      "1698\n",
      "1698\n",
      "London\n",
      "\n",
      "\n",
      "Roper, Abel, 1665-1726\n",
      "unknown\n",
      "1665-01-01\n",
      "1726-02-05\n",
      "77718116\n",
      "\n",
      "\n",
      "RÃ¶per, A.\n",
      "unknown\n",
      "0\n",
      "0\n",
      "194410204\n",
      "\n",
      "\n",
      "Roper, Abel.\n",
      "unknown\n",
      "0\n",
      "0\n",
      "250424859\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "j. cleave\n",
      "\n",
      "\n",
      "\n",
      "12251058\n",
      "832951456\n",
      "861624617\n",
      "891541373\n",
      "A31298\n",
      "\n",
      "12251058\n",
      "832951456\n",
      "861624617\n",
      "891541373\n",
      "93425138\n",
      "77718116\n",
      "194410204\n",
      "250424859\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Created by Matthew Milner (matthew.milner@mcgill.ca) for the Distant Reading Early Modernity Project (DREaM) of Early Modern Conversions using EEBO TCP Phases 1 & 2, OCLC, and VIAF Metadata\n",
      "\n",
      "\n",
      "\n",
      "Normalized using VARD2\n",
      "\n",
      "\n",
      "Confidence values for VIAF matches in publicationStmt are based on name matching and dates of the agent in relation to the particular EEBO title. 0 is a confident match, 1 contains a missing date, 2 only matches a name or a permutation of the name, and no date information is present for comparison in VIAF. Confidence values of 3 or 4 appear for unmatched names. 3 indicates a possible VIAF match, however, due to data inconsistencies no permutations of the canonical name were close enough to permit a confident match. This usually occurs with pseudonyms. A value of 4 failed to find any VIAF matches, however it is clear that the text does or could represent an individual. In many cases strings with two initials (such as M. S.) will mismatch. Any clarifications or edits to this data can be submitted for future revisions.\n",
      "\n",
      "\n",
      "In order to comply with EEBO TCP licensing, each header contains the EEBO TCP Phase number as an attribute in tcpid.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2015-11-16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " THE NEW ATLAS: OR, Travels and Voyages IN Europe, Asia, Africa and America, Through the most Renowned Parts of the WORLD, VIZ.\n",
      "From England to the Dardanelles, thence to Constantinople, Egypt, Palestine, or the Holy Land, Syria, Mesopotamia, Child, Persia, East-India, China, Tartary, Muscovy, and by Poland; the German Empire, Flanders and Holland, to Spain and the West-Indies; with a brief Account of Aethiopia, and the Pilgrimages to Mecha and Medina in Arabia, containing what is Rare and Worthy of Remarks in those vast Countries; relating to Building, Antiquities, Religion, Manners, Customs, Princes, Courts, or Affairs Military and Civil, or whatever else of any kind is worthy of Note.\n",
      "Performed by an English Gentleman, in Nine Years Travel and Voyages, more exact than Ever.\n",
      "LONDON, Printed for J. Cleave in Chanchery-Lane near Serjeant's Inn, and A. Roper at the Black Boy in Fleet-street, 1698.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TO THE Ingenious Reader, THE PREFACE.\n",
      "THE desire of Travel, and Voyaging to distant Lands, is so Natural to an Active Genius, that but few who have not had the opportunity of putting it in Action, have been no less desirable of such an improving undertaking. By what is visible in one's Native Country, there is no exalted Mind but must consequently tend to a higher elevation in Knowledge, to furnish it with a Completion of those wonderful things the scanty Globe Communicates to the Sight and Senses, so to enable one to give a true Judgment in difference of Countries, and\n",
      " what is Rare and Remarkable in them. To this end, Princes have laid aside their Regal Ornaments, and the exuberant Pleasures of Thrones for a time, taking on them the Fatigue of long Journeys, through many dangers and difficulties, that so they might inform themselves of the certainty of things, and Affairs worthy to be entertained in the repositories of Royal Breasts, and to be the concern of Majesty. I need not enumerate Ancient Examples for this, one very Modern may suffice, to evidence Truth of what I Attest. It is well known how the Great and Powerful Czar of Muscovy, in the midst of War shrouding Majesty in a mean disguise; left his Spacious Country and Armies Contesting with the mighty Nations of Turks and Tartars, making a tedious Journey to inform himself in those Matters; of which, at Home, he conceived he had but an imperfect Relation; also to polish his pregnant Genius in the refined Courts of other Princes, and in all probability\n",
      " met with a satisfaction that made him conclude his Time and Travel well bestowed and undertaken.\n",
      "I need not much enforce an Argument to persuade the Ingenious that Travel, renders a Man very much accomplished, and often raises his Fortune above the common level. It has been seen in Ancient and Modern Ages, whilst such as hav  &&&&&&&   Questions, of where I had been, and the particulars of what I observed, at the Request of those that had done so well for me, and now so Lovingly received me, I took leisure time to Write what you have perused, hoping it will give my Country-Men as an entire satisfaction as I have had, in the undertaking and performing my Travels, and then no doubt but both of us will be well pleased.\n",
      "FINIS.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(testSoupText[:5000],\" &&&&&&& \", testSoupText[-400:]) # have a peek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2015-11-16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " THE NEW ATLAS: OR, Travels and Voyages IN Europe, Asia, Africa and America, Through the most Renowned Parts of the WORLD, VIZ.\n",
      "From England to the Dardanelles, thence to Constantinople, Egypt, Palestine, or the Holy Land, Syria, Mesopotamia, Child, Persia, East-India, China, Tartary, Muscovy, and by Poland; the German Empire, Flanders and Holland, to Spain and the West-Indies; with a brief Account of Aethiopia, and the Pilgrimages to Mecha and Medina in Arabia, containing what is Rare and Worthy of Remarks in those vast Countries; relating to Building, Antiquities, Rel\n"
     ]
    }
   ],
   "source": [
    "if \"as an attribute in tcpid.\" in testSoupText:\n",
    "    param, value = testSoupText.split(\"as an attribute in tcpid.\",1)\n",
    "    print(value[:600])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that kind of worked...but there must be a cleaner way to do it, and perhaps to get that date out of there? I hesitate to use the date as the splitting point, since it seems likely that that will change depending on the file (maybe? a cursory look at 5 random files suggests otherwise, but this seems like a *good question for Stefan*. It seems difficult that the splitting/etc. can't be done until after the XML is stripped (although that makes sense considering how BS parses things and converts tags).\n",
    "\n",
    "Hypothetically, I should be able to put the stripping and then the header cuts into a loop and run my texts through them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, as a wrap-up to this little experiment, what questions and thoughts do I have?\n",
    "\n",
    "- how much resources is it going to take to prep all my data? Stripping XML, stripping headers, etc.?\n",
    "- is it better to use plain text (VARDed), considering that otherwise I'm going to have to strip these files, but also the ~40k files that I'll be running through machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
